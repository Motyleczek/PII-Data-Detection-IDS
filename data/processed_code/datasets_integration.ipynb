{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excel Section\n",
    "## Na razie nie działa bo nie mam pomysłu na zrobienie kolumny labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>400</td>\n",
       "      <td>When the young people returned to the ballroom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>401</td>\n",
       "      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>402</td>\n",
       "      <td>As Roger had predicted, the snow departed as q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>403</td>\n",
       "      <td>Mr. Grimes was to come up next morning to Sir ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>404</td>\n",
       "      <td>And outside before the palace a great garden w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document                                          full_text\n",
       "0       400  When the young people returned to the ballroom...\n",
       "1       401  All through dinner time, Mrs. Fayre was somewh...\n",
       "2       402  As Roger had predicted, the snow departed as q...\n",
       "3       403  Mr. Grimes was to come up next morning to Sir ...\n",
       "4       404  And outside before the palace a great garden w..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wczytanie danych z pliku Excel\n",
    "excel_data = pd.read_excel('CLEAR_corpus_final.xlsx')\n",
    "# nazwy kolumn, które chcemy zachować\n",
    "columns_to_keep = ['ID', 'Excerpt']  \n",
    "# Zachowanie tylko wybranych kolumn\n",
    "excel_data = excel_data.loc[:, columns_to_keep]\n",
    "# Dostosowanie nazw kolumn dla danych z excela\n",
    "excel_data.rename(columns={'ID': 'document', 'Excerpt': 'full_text'}, inplace=True)\n",
    "excel_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_newlines_and_remove_escapes(text):\n",
    "    # Usunięcie znaków ucieczki przed apostrofami\n",
    "    text = re.sub(r\"\\\\'\", \"'\", text)\n",
    "    # Usunięcie znaków ucieczki\n",
    "    text = re.sub(r'\\\\', '', text)\n",
    "    # Zamiana znaków nowej linii na \\n\\n\n",
    "    text = re.sub(r'(?<!\\\\)\\n', '\\n\\n', text)\n",
    "    return text\n",
    "\n",
    "# Apply the function to the 'full_text' column\n",
    "excel_data['full_text'] = excel_data['full_text'].apply(replace_newlines_and_remove_escapes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytanie modelu języka angielskiego\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "# Funkcja do tokenizacji tekstu i sprawdzenia, czy token kończy się białym znakiem\n",
    "def tokenize_and_check_whitespace(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.text for token in doc]\n",
    "    trailing_whitespace = [token.whitespace_ != '' for token in doc]\n",
    "    return tokens, trailing_whitespace\n",
    "\n",
    "# Dodanie kolumn 'tokens' i 'trailing_whitespace'\n",
    "excel_data[['tokens', 'trailing_whitespace']] = excel_data['full_text'].apply(tokenize_and_check_whitespace).apply(pd.Series)\n",
    "excel_data.to_json('excel.json', orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pomysły z internetu trzeba się nad tym zastanowić"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def label_entities(text):\n",
    "#     # Przetworzenie tekstu za pomocą modelu spaCy\n",
    "#     doc = nlp(text)\n",
    "#     # Utworzenie listy etykiet\n",
    "#     labels = ['O'] * len(doc)\n",
    "#     # Oznaczanie nazw osób\n",
    "#     for ent in doc.ents:\n",
    "#         if ent.label_ == 'PERSON':\n",
    "#             for i in range(ent.start, ent.end):\n",
    "#                 labels[i] = 'B-NAME_STUDENT' if i == ent.start else 'I-NAME_STUDENT'\n",
    "#         elif ent.label_ == 'EMAIL':\n",
    "#             for i in range(ent.start, ent.end):\n",
    "#                 labels[i] = 'I-EMAIL_STUDENT'\n",
    "#         elif ent.label_ == 'PHONE_NUM':\n",
    "#             for i in range(ent.start, ent.end):\n",
    "#                 labels[i] = 'I-PHONE_NUM_STUDENT'\n",
    "#         elif ent.label_ == 'URL':\n",
    "#             for i in range(ent.start, ent.end):\n",
    "#                 labels[i] = 'I-URL_PERSONAL'\n",
    "#         elif ent.label_ == 'GPE':\n",
    "#             for i in range(ent.start, ent.end):\n",
    "#                 labels[i] = 'I-STREET_ADDRESS'\n",
    "#         # Dodaj inne etykiety według potrzeb (np. USERNAME, ID_NUM)\n",
    "\n",
    "#     return labels\n",
    "\n",
    "# excel_data[['labels']] = excel_data['full_text'].apply(label_entities)\n",
    "# excel_data.to_json('excel.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# import pandas as pd\n",
    "\n",
    "# # Wczytanie modelu spaCy\n",
    "# nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# def label_entities(text):\n",
    "#     # Przetworzenie tekstu za pomocą modelu spaCy\n",
    "#     doc = nlp(text)\n",
    "#     # Utworzenie listy etykiet\n",
    "#     labels = ['O'] * len(doc)\n",
    "#     # Oznaczanie nazw osób, adresów e-mail itp. (jak w poprzednich przykładach)\n",
    "\n",
    "#     return labels\n",
    "\n",
    "# # Przykładowy tekst podzielony na słowa\n",
    "\n",
    "# # Otagowanie słów\n",
    "# labels = excel_data['full_text'].apply(label_entities)\n",
    "# print(labels)\n",
    "\n",
    "\n",
    "# excel_data['labels']  = labels\n",
    "\n",
    "# # Zapis do pliku JSON\n",
    "# excel_data.to_json('excel.json', orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from textblob import TextBlob\n",
    "# import nltk\n",
    "\n",
    "\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('punkt')\n",
    "\n",
    "# def tag_data(text):\n",
    "#     blob = TextBlob(text)\n",
    "#     tagged_text = []\n",
    "\n",
    "#     for word, pos in blob.tags:\n",
    "#         if pos == 'NNP':  # NN (rzeczownik, pojedyncza liczba), NNP (rzeczownik, pojedyncza liczba, właściwa nazwa)\n",
    "#             tagged_text.append((word, 'NAME_STUDENT'))\n",
    "#         elif '@' in word:\n",
    "#             tagged_text.append((word, 'USERNAME'))\n",
    "#         elif '.' in word and '@' in word:\n",
    "#             tagged_text.append((word, 'EMAIL'))\n",
    "#         # Dodaj więcej warunków dla innych etykiet, takich jak ID_NUM, PHONE_NUM, URL_PERSONAL itp.\n",
    "\n",
    "#     return tagged_text\n",
    "\n",
    "\n",
    "# text = \"My name is Szymon Dobrowoslki, email is john.doe@example.com and my student ID is 123456789012.\"\n",
    "# tags = tag_data(text)\n",
    "# print(tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zapis do formatu `json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excel_data.to_json('excel.json', orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV SECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Koncept*\n",
    "\n",
    "Plan jest taki żeby przetworzyć dane tak by pasowały do pliku konkursowego. Z racji że dane które znalazłem były podzielone w dość specyficzny sposób, zawierały jedną kolumnę `text` \n",
    "\n",
    "Przykład wiersza\n",
    "\n",
    "`<s>[INST] I need a summary of the book Existential Therapy: 100 Key Points and Techniques for Van Kilback. Can you help? [/INST] I need a summary of the book Existential Therapy: 100 Key Points and Techniques for [FULLNAME]. Can you help? </s>`\n",
    "\n",
    "stwierdziłem że podziele ję na 2 kolumny `full_text` zgodną z konkursem i tymczasową kolumnę `tagged_text` która posłuży do stworzenia kolumny labels będzie to tekst który zawiera tag(tekst po `[/INST]`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nieprzydatne, zapomniałem o kolumnie labels, przestało działać"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wczytanie danych csv, usunięcie oznaczeń, doadanie full_text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytanie danych z pliku CSV\n",
    "csv_data = pd.read_csv('PII-Redaction.csv') \n",
    "# Wyrażenie regularne do wydobycia żądanej części tekstu\n",
    "pattern = r\"\\[INST\\](.*?)\\[/INST\\]\"\n",
    "\n",
    "# Funkcja do wyodrębnienia żądanej części tekstu z każdego wiersza\n",
    "def extract_text(text):\n",
    "    matches = re.findall(pattern, text)\n",
    "    if matches:\n",
    "        return matches[0].strip()  # Zwracamy pierwsze dopasowanie, usuwając ewentualne białe znaki na początku i końcu\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Wydobycie tekstu z każdego wiersza w kolumnie \"full_text\"\n",
    "csv_data['full_text'] = csv_data['text'].apply(extract_text)\n",
    "csv_data.drop(columns='text')\n",
    "\n",
    "# Zapisanie zmodyfikowanych danych do pliku CSV - kolumna full_text z usuniętymmi oznaczeniami\n",
    "csv_data.to_csv('first_mod_csv.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### standaryzacja tekstu w full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_csv(input_file, output_file):\n",
    "    # Wczytaj plik CSV\n",
    "    data = pd.read_csv(input_file)\n",
    "\n",
    "    # Ustandaryzuj każdy wiersz\n",
    "    data['full_text'] = data['full_text'].apply(lambda x: '\"' + re.sub(r'^\\d+\\.\\s*', '', x.strip('\"\"').strip()) + '\"' if not x.startswith('\"') else x)\n",
    "    # zamiana \\ na \\n\\n ja w pliku konkursowym\n",
    "    data['full_text'] = data['full_text'].str.replace('\\\\', '\\n\\n')\n",
    "    # Zapisz do pliku CSV w taki sposób żeby nie było w \"\"\"\"\"\"\n",
    "    data.to_csv(output_file, index=False, quoting=csv.QUOTE_NONE, escapechar='\\\\')\n",
    "\n",
    "# Przykładowe użycie funkcji\n",
    "standardize_csv('first_mod_csv.csv', 'second_mod_csv.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dodanie kolumn, document, tokens, trailing_whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\szydo\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\szydo\\AppData\\Local\\Temp\\ipykernel_22288\\3497299016.py\", line 2, in <module>\n",
      "    csv_data = pd.read_csv('./second_mod_csv.csv')\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\szydo\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 912, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\szydo\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 583, in _read\n",
      "    return parser.read(nrows)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\szydo\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1704, in read\n",
      "    ) = self._engine.read(  # type: ignore[attr-defined]\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\szydo\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\", line 234, in read\n",
      "    chunks = self._reader.read_low_memory(nrows)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"pandas\\_libs\\parsers.pyx\", line 814, in pandas._libs.parsers.TextReader.read_low_memory\n",
      "  File \"pandas\\_libs\\parsers.pyx\", line 875, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"pandas\\_libs\\parsers.pyx\", line 850, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"pandas\\_libs\\parsers.pyx\", line 861, in pandas._libs.parsers.TextReader._check_tokenize_status\n",
      "  File \"pandas\\_libs\\parsers.pyx\", line 2029, in pandas._libs.parsers.raise_parser_error\n",
      "pandas.errors.ParserError: Error tokenizing data. C error: Expected 2 fields in line 5, saw 4\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\szydo\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\szydo\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\szydo\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\szydo\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\szydo\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\szydo\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\szydo\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\szydo\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\szydo\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\szydo\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\szydo\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\core.py\", line 677, in included_pieces\n",
      "    scope_pieces = self.scope_pieces\n",
      "                   ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\szydo\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\szydo\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\core.py\", line 614, in scope_pieces\n",
      "    scope_start, scope_end = self.source.line_range(self.scope)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\szydo\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\core.py\", line 178, in line_range\n",
      "    return line_range(self.asttext(), node)\n",
      "                      ^^^^^^^^^^^^\n",
      "AttributeError: 'Source' object has no attribute 'asttext'\n"
     ]
    }
   ],
   "source": [
    "# Wczytanie danych z pliku CSV\n",
    "csv_data = pd.read_csv('second_mod_csv.csv')\n",
    "\n",
    "# Dodanie kolumny 'document'\n",
    "csv_data['document'] = range(1, len(csv_data) + 1)\n",
    "\n",
    "# Wczytanie modelu języka angielskiego\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Funkcja do tokenizacji tekstu i sprawdzenia, czy token kończy się białym znakiem\n",
    "def tokenize_and_check_whitespace(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.text for token in doc]\n",
    "    trailing_whitespace = [token.whitespace_ != '' for token in doc]\n",
    "    return tokens, trailing_whitespace\n",
    "\n",
    "# Dodanie kolumn 'tokens' i 'trailing_whitespace'\n",
    "csv_data[['tokens', 'trailing_whitespace']] = csv_data['full_text'].apply(tokenize_and_check_whitespace).apply(pd.Series)\n",
    "\n",
    "csv_data = csv_data[['document','full_text','tokens', 'trailing_whitespace']]\n",
    "\n",
    "# Zapisanie DataFrame jako plik JSON\n",
    "\n",
    "csv_data.to_csv('csv_with_added_columns.csv')\n",
    "csv_data.to_json('csv.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### usunięcie ostatniego elementu w trailing_whitespace ponieważ zliczało miejsce między .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\szydo\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\szydo\\AppData\\Local\\Temp\\ipykernel_22288\\2694230180.py\", line 1, in <module>\n",
      "    csv_json_data = pd.read_json('csv.json')\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\szydo\\anaconda3\\Lib\\site-packages\\pandas\\io\\json\\_json.py\", line 760, in read_json\n",
      "    json_reader = JsonReader(\n",
      "                  ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\szydo\\anaconda3\\Lib\\site-packages\\pandas\\io\\json\\_json.py\", line 861, in __init__\n",
      "    data = self._get_data_from_filepath(filepath_or_buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\szydo\\anaconda3\\Lib\\site-packages\\pandas\\io\\json\\_json.py\", line 917, in _get_data_from_filepath\n",
      "    raise FileNotFoundError(f\"File {filepath_or_buffer} does not exist\")\n",
      "FileNotFoundError: File csv.json does not exist\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\szydo\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\szydo\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\szydo\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\szydo\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\szydo\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\szydo\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\szydo\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\szydo\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\szydo\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\szydo\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\szydo\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\core.py\", line 677, in included_pieces\n",
      "    scope_pieces = self.scope_pieces\n",
      "                   ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\szydo\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\szydo\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\core.py\", line 614, in scope_pieces\n",
      "    scope_start, scope_end = self.source.line_range(self.scope)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\szydo\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\core.py\", line 178, in line_range\n",
      "    return line_range(self.asttext(), node)\n",
      "                      ^^^^^^^^^^^^\n",
      "AttributeError: 'Source' object has no attribute 'asttext'\n"
     ]
    }
   ],
   "source": [
    "csv_json_data = pd.read_json('csv.json')\n",
    "#usuwa ostatni element w trailing_whitespace ponieważ zalicz do zakresu element między znakiem na końcu zdania i \" np. .\"\n",
    "csv_json_data['trailing_whitespace'] = csv_json_data['trailing_whitespace'].apply(lambda x: x[:-1] if x[-1] is False else x)\n",
    "# ponowne zapisanie pliku\n",
    "csv_json_data.to_json('csv.json', orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Właściwa implementacja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wczytanie danych i stworzenie pliku z tagged_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytaj dane z pliku CSV\n",
    "csv_data_tagged = pd.read_csv('PII-Redaction.csv') \n",
    "\n",
    "def extract_text_after_tag(text):\n",
    "    \"\"\"funkcja wyodrębnia tekst po tagu [/INST]\"\"\"\n",
    "    if '[/INST]' in text:\n",
    "        split_text = text.split('[/INST]')\n",
    "        extracted_text = split_text[1].strip() if len(split_text) > 1 else None\n",
    "        return extracted_text.replace('</s>', '').strip() if extracted_text else None\n",
    "    else:\n",
    "        return text.strip().replace('</s>', '')\n",
    "\n",
    "\n",
    "\n",
    "# Wyrażenie regularne do wydobycia żądanej części tekstu\n",
    "pattern = r\"\\[INST\\](.*?)\\[/INST\\]\"\n",
    "def extract_text(text):\n",
    "    \"\"\"wyodrębnienia żądanej części tekstu z każdego wiersza\"\"\"\n",
    "    matches = re.findall(pattern, text)\n",
    "    if matches:\n",
    "        return matches[0].strip()  # Zwracamy pierwsze dopasowanie, usuwając ewentualne białe znaki na początku i końcu\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Wydobycie tekstu z każdego wiersza do kolumny full_text\n",
    "csv_data_tagged['full_text'] = csv_data_tagged['text'].apply(extract_text)\n",
    "\n",
    "# Wydobycie tekstu z każdego wiersza  ztagami do kolumny tagged_text\n",
    "csv_data_tagged['tagged_text'] = csv_data_tagged['text'].apply(extract_text_after_tag)\n",
    "\n",
    "# nazwy kolumn, które chcemy zachować\n",
    "column_to_keep = ['full_text', 'tagged_text']\n",
    "\n",
    "# Zachowanie tylko wybranej kolumny\n",
    "csv_data_tagged = csv_data_tagged.loc[:, column_to_keep]\n",
    "\n",
    "# Zapisanie zmodyfikowanych danych do pliku CSV - kolumna full_text z usuniętymi oznaczeniami\n",
    "csv_data_tagged.to_csv('full_tag_csv.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standaryzacja tekstu w full_text i tagged_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nie działa tak jak planowałem i nie do końca wiem dlaczego w sensie nie zamienia \\ na \\n\\n\n",
    "def standardize_tagged_csv(input_file, output_file):\n",
    "    # Wczytaj plik CSV\n",
    "    data = pd.read_csv(input_file)\n",
    "\n",
    "    # Ustandaryzuj każdy wiersz\n",
    "    data['full_text'] = data['full_text'].apply(lambda x: '\"' + re.sub(r'^\\d+\\.\\s*', '', x.strip('\"\"').strip()) + '\"' if not x.startswith('\"') else x)\n",
    "    data['tagged_text'] = data['tagged_text'].apply(lambda x: '\"' + re.sub(r'^\\d+\\.\\s*', '', x.strip('\"\"').strip()) + '\"' if not x.startswith('\"') else x)\n",
    "    # zamiana \\ na \\n\\n jak w pliku konkursowym\n",
    "    data['full_text'] = data['full_text'].str.replace(r'\\\\', r'\\n\\n')\n",
    "    data['tagged_text'] = data['tagged_text'].str.replace(r'\\\\', r'\\n\\n')\n",
    "    # Zapisz do pliku CSV w taki sposób żeby nie było w \"\"\"\"\"\"\n",
    "    data.to_csv(output_file, index=False, quoting=csv.QUOTE_NONE, escapechar='\\n')\n",
    "\n",
    "# Przykładowe użycie funkcji\n",
    "standardize_tagged_csv('full_tag_csv.csv', 'full_tag_std_csv.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dodanie kolumn, document, tokens, trailing_whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytanie danych z pliku CSV\n",
    "csv_data_tagged = pd.read_csv('full_tag_std_csv.csv')\n",
    "\n",
    "# Dodanie kolumny 'document'\n",
    "csv_data_tagged['document'] = range(1, len(csv_data_tagged) + 1)\n",
    "\n",
    "# Wczytanie modelu języka angielskiego\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Funkcja do tokenizacji tekstu i sprawdzenia, czy token kończy się białym znakiem\n",
    "def tokenize_and_check_whitespace(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.text for token in doc]\n",
    "    trailing_whitespace = [token.whitespace_ != '' for token in doc]\n",
    "    return tokens, trailing_whitespace\n",
    "\n",
    "# Dodanie kolumn 'tokens' i 'trailing_whitespace'\n",
    "csv_data_tagged[['tokens', 'trailing_whitespace']] = csv_data_tagged['full_text'].apply(tokenize_and_check_whitespace).apply(pd.Series)\n",
    "\n",
    "csv_data_tagged = csv_data_tagged[['document','full_text','tokens', 'trailing_whitespace', 'tagged_text']]\n",
    "\n",
    "\n",
    "\n",
    "csv_data_tagged.to_csv('csv_tagged_with_added_columns.csv', index=False)\n",
    "# Zapisanie DataFrame jako plik JSON\n",
    "csv_data_tagged.to_json('csv_tagged.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dodanie labels do pliku z kolumną z tagami"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stara wersja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To nie uwzględniało [FIRSTNAME] [LASTNAME] we właściwy sposób\n",
    "# def assign_labels(tagged_text):\n",
    "#     words = tagged_text.split()\n",
    "#     labels = []\n",
    "#     for i, word in enumerate(words):\n",
    "#         if '[' in word:\n",
    "#             # Wyciągamy tag bez dodatkowych znaków\n",
    "#             tag = word.split('[')[-1].split(']')[0].upper()\n",
    "#             if tag == 'FULLNAME':\n",
    "#                     labels.append(\"B-NAME-STUDENT\")\n",
    "#                     labels.append(\"I-NAME-STUDENT\") \n",
    "#             elif tag in ['FIRSTNAME', 'LASTNAME']:\n",
    "#                 labels.append(\"B-NAME-STUDENT\")\n",
    "#             elif tag == 'EMAIL':    \n",
    "#                 labels.append(\"B-EMAIL\")\n",
    "#             elif tag in ['USERNAME', 'DISPLAYNAME']:\n",
    "#                 labels.append(\"B-USERNAME\")\n",
    "#             else:\n",
    "#                 labels.append('O')\n",
    "#         else:\n",
    "#             labels.append('O')\n",
    "#     return labels\n",
    "\n",
    "# # Wczytanie danych z pliku CSV\n",
    "# csv_data = pd.read_csv('csv_tagged_with_added_columns.csv') \n",
    "\n",
    "# # Dodanie kolumny z etykietami\n",
    "# csv_data['labels'] = csv_data['tagged_text'].apply(assign_labels)\n",
    "\n",
    "# # Zapisanie zmodyfikowanych danych do pliku CSV\n",
    "# csv_data.to_csv('csv_tagged_with_labels.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Poprawione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_labels(tagged_text):\n",
    "    \"\"\"funkcja do tworzenia listy labeli zgodnie z opisem konkursu, robi to na podstaw\"\"\"\n",
    "    words = tagged_text.split()\n",
    "    labels = []\n",
    "    for i, word in enumerate(words):\n",
    "        if '[' in word:\n",
    "            # Wyciągamy tag bez dodatkowych znaków\n",
    "            tag = word.split('[')[-1].split(']')[0].upper()\n",
    "            if tag == 'FIRSTNAME':\n",
    "                # Sprawdzamy, czy kolejne tagi po pierwszym tagu imienia to nazwisko\n",
    "                next_word_index = i + 1\n",
    "                if next_word_index < len(words) and '[LASTNAME]' in words[next_word_index]:\n",
    "                    labels.append(\"B-NAME-STUDENT\")\n",
    "                    labels.append(\"I-NAME-STUDENT\")\n",
    "                else:\n",
    "                    labels.append(\"B-NAME-STUDENT\")\n",
    "            elif tag == 'LASTNAME':\n",
    "                # Sprawdzamy, czy poprzedni tag to imię\n",
    "                prev_word_index = i - 1\n",
    "                if prev_word_index >= 0 and '[FIRSTNAME]' in words[prev_word_index]:\n",
    "                    continue  # Pomijamy przypisanie etykiety w tym przypadku\n",
    "                else:\n",
    "                    labels.append(\"B-NAME-STUDENT\")\n",
    "            elif tag == 'FULLNAME':\n",
    "                # Sprawdzamy, czy lista labels ma co najmniej dwa elementy\n",
    "                    labels.append(\"B-NAME-STUDENT\")\n",
    "                    labels.append(\"I-NAME-STUDENT\") \n",
    "            elif tag == 'EMAIL':    \n",
    "                labels.append(\"B-EMAIL\")\n",
    "            elif tag in ['USERNAME', 'DISPLAYNAME']:\n",
    "                labels.append(\"B-USERNAME\")\n",
    "            else:\n",
    "                labels.append('O')\n",
    "        else:\n",
    "            labels.append('O')\n",
    "    return labels\n",
    "\n",
    "# Wczytanie danych z pliku CSV\n",
    "csv_data = pd.read_csv('csv_tagged_with_added_columns.csv') \n",
    "\n",
    "# Dodanie kolumny z etykietami\n",
    "csv_data['labels'] = csv_data['tagged_text'].apply(assign_labels)\n",
    "\n",
    "# Zapisanie zmodyfikowanych danych do pliku CSV\n",
    "csv_data.to_csv('csv_tagged_with_labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usunięcie kolumny tagged-text, zapis do właściwego formatu `json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data = pd.read_csv('csv_tagged_with_labels.csv')\n",
    "\n",
    "csv_data.drop(columns=['tagged_text'], inplace=True)\n",
    "\n",
    "csv_data.to_csv('final_csv_ready_to_merge.csv', index=False)\n",
    "csv_data.to_json('csv_almost_ready.json', orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usunięcie z kolumny `trailing_whitespace` ostatniego `false` ponieważ zlicza łączenie znaków(?/!/.) z \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_json_data = pd.read_json('csv_almost_ready.json')\n",
    "# usuwa ostatnie false z trailing_whitespace\n",
    "csv_json_data['trailing_whitespace'] = csv_json_data['trailing_whitespace'].apply(lambda x: x[:-1] if x[-1] is False else x)\n",
    "csv_json_data.to_json('final_csv.json', orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Łączenie plików "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wczytanie pliku json, sortowanie od największego do najmniejszego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>full_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>trailing_whitespace</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6806</th>\n",
       "      <td>22687</td>\n",
       "      <td>Mind Mapping\\n\\nChallenge\\n\\nMy consulting tea...</td>\n",
       "      <td>[Mind, Mapping, \\n\\n, Challenge, \\n\\n, My, con...</td>\n",
       "      <td>[True, False, False, False, False, True, True,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805</th>\n",
       "      <td>22684</td>\n",
       "      <td>Brainstorming\\n\\nChallenge &amp; Selection\\n\\nBrai...</td>\n",
       "      <td>[Brainstorming, \\n\\n, Challenge, &amp;, Selection,...</td>\n",
       "      <td>[False, False, True, True, False, False, True,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6804</th>\n",
       "      <td>22681</td>\n",
       "      <td>Challenge\\n\\nSo, a few months back, I had chos...</td>\n",
       "      <td>[Challenge, \\n\\n, So, ,, a, few, months, back,...</td>\n",
       "      <td>[False, False, False, True, True, True, True, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6803</th>\n",
       "      <td>22679</td>\n",
       "      <td>Why Mind Mapping?\\n\\nMind maps are graphical r...</td>\n",
       "      <td>[Why, Mind, Mapping, ?, \\n\\n, Mind, maps, are,...</td>\n",
       "      <td>[True, True, False, False, False, True, True, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6802</th>\n",
       "      <td>22678</td>\n",
       "      <td>EXAMPLE – JOURNEY MAP\\n\\nTHE CHALLENGE    My w...</td>\n",
       "      <td>[EXAMPLE, –, JOURNEY, MAP, \\n\\n, THE, CHALLENG...</td>\n",
       "      <td>[True, True, True, False, False, True, True, F...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>Assignment:  Visualization Reflection  Submitt...</td>\n",
       "      <td>[Assignment, :,   , Visualization,  , Reflecti...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, B-NAME_ST...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>Design Thinking for Innovation\\n\\nSindy Samaca...</td>\n",
       "      <td>[Design, Thinking, for, Innovation, \\n\\n, Sind...</td>\n",
       "      <td>[True, True, True, False, False, True, False, ...</td>\n",
       "      <td>[O, O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...</td>\n",
       "      <td>[Reporting, process, \\n\\n, by, Gilberto, Gambo...</td>\n",
       "      <td>[True, False, False, True, True, False, False,...</td>\n",
       "      <td>[O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...</td>\n",
       "      <td>[Diego, Estrada, \\n\\n, Design, Thinking, Assig...</td>\n",
       "      <td>[True, False, False, True, True, False, False,...</td>\n",
       "      <td>[B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>Design Thinking for innovation reflexion-Avril...</td>\n",
       "      <td>[Design, Thinking, for, innovation, reflexion,...</td>\n",
       "      <td>[True, True, True, True, False, False, True, F...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6807 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      document                                          full_text  \\\n",
       "6806     22687  Mind Mapping\\n\\nChallenge\\n\\nMy consulting tea...   \n",
       "6805     22684  Brainstorming\\n\\nChallenge & Selection\\n\\nBrai...   \n",
       "6804     22681  Challenge\\n\\nSo, a few months back, I had chos...   \n",
       "6803     22679  Why Mind Mapping?\\n\\nMind maps are graphical r...   \n",
       "6802     22678  EXAMPLE – JOURNEY MAP\\n\\nTHE CHALLENGE    My w...   \n",
       "...        ...                                                ...   \n",
       "4           56  Assignment:  Visualization Reflection  Submitt...   \n",
       "3           20  Design Thinking for Innovation\\n\\nSindy Samaca...   \n",
       "2           16  Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...   \n",
       "1           10  Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...   \n",
       "0            7  Design Thinking for innovation reflexion-Avril...   \n",
       "\n",
       "                                                 tokens  \\\n",
       "6806  [Mind, Mapping, \\n\\n, Challenge, \\n\\n, My, con...   \n",
       "6805  [Brainstorming, \\n\\n, Challenge, &, Selection,...   \n",
       "6804  [Challenge, \\n\\n, So, ,, a, few, months, back,...   \n",
       "6803  [Why, Mind, Mapping, ?, \\n\\n, Mind, maps, are,...   \n",
       "6802  [EXAMPLE, –, JOURNEY, MAP, \\n\\n, THE, CHALLENG...   \n",
       "...                                                 ...   \n",
       "4     [Assignment, :,   , Visualization,  , Reflecti...   \n",
       "3     [Design, Thinking, for, Innovation, \\n\\n, Sind...   \n",
       "2     [Reporting, process, \\n\\n, by, Gilberto, Gambo...   \n",
       "1     [Diego, Estrada, \\n\\n, Design, Thinking, Assig...   \n",
       "0     [Design, Thinking, for, innovation, reflexion,...   \n",
       "\n",
       "                                    trailing_whitespace  \\\n",
       "6806  [True, False, False, False, False, True, True,...   \n",
       "6805  [False, False, True, True, False, False, True,...   \n",
       "6804  [False, False, False, True, True, True, True, ...   \n",
       "6803  [True, True, False, False, False, True, True, ...   \n",
       "6802  [True, True, True, False, False, True, True, F...   \n",
       "...                                                 ...   \n",
       "4     [False, False, False, False, False, False, Fal...   \n",
       "3     [True, True, True, False, False, True, False, ...   \n",
       "2     [True, False, False, True, True, False, False,...   \n",
       "1     [True, False, False, True, True, False, False,...   \n",
       "0     [True, True, True, True, False, False, True, F...   \n",
       "\n",
       "                                                 labels  \n",
       "6806  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "6805  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "6804  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "6803  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "6802  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "...                                                 ...  \n",
       "4     [O, O, O, O, O, O, O, O, O, O, O, O, B-NAME_ST...  \n",
       "3     [O, O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT...  \n",
       "2     [O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O...  \n",
       "1     [B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...  \n",
       "0     [O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...  \n",
       "\n",
       "[6807 rows x 5 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_json('train.json')\n",
    "train_data.sort_values('document', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### połączenie danych zmiana numeracji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytanie danych z plików JSON\n",
    "train_data = pd.read_json('train.json')\n",
    "csv_data = pd.read_json('final_csv.json')\n",
    "# excel_data = pd.read_json('excel.json')\n",
    "\n",
    "# Ustalenie początkowego numeru dokumentu dla danych z plików excel.json i csv.json\n",
    "next_document_number = train_data['document'].max() + 1\n",
    "\n",
    "# Aktualizacja numerów dokumentów w danych z plików excel.json i csv.json\n",
    "# excel_data['document'] = range(next_document_number, next_document_number + len(excel_data))\n",
    "# csv_data['document'] = range(next_document_number + len(excel_data), next_document_number + len(excel_data) + len(csv_data))\n",
    "csv_data['document'] = range(next_document_number, next_document_number + len(csv_data))\n",
    "\n",
    "# Dodanie danych z plików excel.json i csv.json do danych z pliku train.json\n",
    "# train_data = pd.concat([train_data, excel_data, csv_data], ignore_index=True)\n",
    "train_data = pd.concat([train_data, csv_data], ignore_index=True)\n",
    "\n",
    "# Zapisanie połączonych danych do pliku train.json\n",
    "train_data.to_json('new_train.json', orient='records')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
